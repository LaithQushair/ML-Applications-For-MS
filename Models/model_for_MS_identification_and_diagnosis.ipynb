{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8AJNVGfGypj",
        "outputId": "6c5563e1-f57c-43a6-bebc-027b850af447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/dataset/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUpCBQ-Ejt7M",
        "outputId": "5f696b88-b0b4-419c-b71b-d3b4ca980c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control  MS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WXL3JNM64ea",
        "outputId": "3fca1c48-7914-44f5-9b42-81c41100ddae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training 1000 MS and Control data using VGG model"
      ],
      "metadata": {
        "id": "Z-6zHux3lSSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms # Corrected the import statement\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Define transformations for training and testing\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Set up dataset paths (assume images are organized into 'Control' and 'MS' subfolders)\n",
        "dataset_path = '/content/drive/MyDrive/dataset'\n",
        "\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=data_transforms['train'])\n",
        "\n",
        "\n",
        "# Split dataset (65% train, 15% validation, 20% test)\n",
        "train_size = int(0.65 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
        "\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# VGG16 has a classifier attribute instead of fc\n",
        "num_features = model.classifier[6].in_features  # Get the input features of the last layer in the classifier\n",
        "model.classifier[6] = nn.Linear(num_features, 2)  # Modify the last layer for binary classification\n",
        "\n",
        "# Set up training device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training and validation loop\n",
        "num_epochs = 10\n",
        "best_val_accuracy = 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_preds += torch.sum(preds == labels.data)\n",
        "        total_preds += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_accuracy = correct_preds.double() / len(train_loader.dataset)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_correct += torch.sum(preds == labels.data)\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = val_correct.double() / len(val_loader.dataset)\n",
        "\n",
        "    # Save the model if validation accuracy improves\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), 'best_resnet18_model.pth')\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "# Testing phase\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_correct += torch.sum(preds == labels.data)\n",
        "        test_total += labels.size(0)\n",
        "\n",
        "test_accuracy = test_correct.double() / len(test_loader.dataset)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Save final model after training\n",
        "torch.save(model.state_dict(), 'final_models.vgg16_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zTBafaKGRgK",
        "outputId": "d79eb7ab-62be-4158-93a7-e66246d9c4df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.5656, Train Acc: 0.7053, Val Loss: 0.4138, Val Acc: 0.7949\n",
            "Epoch 2/10, Train Loss: 0.4198, Train Acc: 0.8095, Val Loss: 0.2723, Val Acc: 0.9077\n",
            "Epoch 3/10, Train Loss: 0.2671, Train Acc: 0.8817, Val Loss: 0.3005, Val Acc: 0.8410\n",
            "Epoch 4/10, Train Loss: 0.2587, Train Acc: 0.8970, Val Loss: 0.4472, Val Acc: 0.7744\n",
            "Epoch 5/10, Train Loss: 0.1433, Train Acc: 0.9420, Val Loss: 0.2044, Val Acc: 0.9026\n",
            "Epoch 6/10, Train Loss: 0.1745, Train Acc: 0.9456, Val Loss: 0.1749, Val Acc: 0.9487\n",
            "Epoch 7/10, Train Loss: 0.0988, Train Acc: 0.9621, Val Loss: 0.1374, Val Acc: 0.9487\n",
            "Epoch 8/10, Train Loss: 0.0779, Train Acc: 0.9751, Val Loss: 0.2946, Val Acc: 0.8923\n",
            "Epoch 9/10, Train Loss: 0.0918, Train Acc: 0.9598, Val Loss: 0.1568, Val Acc: 0.9436\n",
            "Epoch 10/10, Train Loss: 0.0304, Train Acc: 0.9941, Val Loss: 0.1951, Val Acc: 0.9333\n",
            "Test Accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model using ResNet 18"
      ],
      "metadata": {
        "id": "ZjJV_uprljQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#from torchvision import datasets, models, transforams\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Define transformations for training and testing\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Set up dataset paths (assume images are organized into 'Control' and 'MS' subfolders)\n",
        "dataset_path = '/content/drive/MyDrive/dataset'\n",
        "\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=data_transforms['train'])\n",
        "\n",
        "\n",
        "# Split dataset (65% train, 15% validation, 20% test)\n",
        "train_size = int(0.65 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
        "\n",
        "# Load pretrained ResNet-18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)  # Modify output layer for binary classification (Healthy vs MS)\n",
        "\n",
        "# Set up training device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training and validation loop\n",
        "num_epochs = 10\n",
        "best_val_accuracy = 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_preds += torch.sum(preds == labels.data)\n",
        "        total_preds += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_accuracy = correct_preds.double() / len(train_loader.dataset)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_correct += torch.sum(preds == labels.data)\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = val_correct.double() / len(val_loader.dataset)\n",
        "\n",
        "    # Save the model if validation accuracy improves\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), 'best_resnet18_model.pth')\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "# Testing phase\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_correct += torch.sum(preds == labels.data)\n",
        "        test_total += labels.size(0)\n",
        "\n",
        "test_accuracy = test_correct.double() / len(test_loader.dataset)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Save final model after training\n",
        "torch.save(model.state_dict(), 'final_resnet18_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7Dd_iL45YPl",
        "outputId": "83d20105-d87a-4b6b-ac83-0ff13f9a2b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 188MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.4875, Train Acc: 0.7586, Val Loss: 0.3867, Val Acc: 0.8205\n",
            "Epoch 2/10, Train Loss: 0.2939, Train Acc: 0.8769, Val Loss: 0.3341, Val Acc: 0.8410\n",
            "Epoch 3/10, Train Loss: 0.2130, Train Acc: 0.9148, Val Loss: 0.3265, Val Acc: 0.8410\n",
            "Epoch 4/10, Train Loss: 0.1425, Train Acc: 0.9467, Val Loss: 0.2726, Val Acc: 0.8821\n",
            "Epoch 5/10, Train Loss: 0.1201, Train Acc: 0.9633, Val Loss: 0.1959, Val Acc: 0.9077\n",
            "Epoch 6/10, Train Loss: 0.0792, Train Acc: 0.9763, Val Loss: 0.3527, Val Acc: 0.8615\n",
            "Epoch 7/10, Train Loss: 0.1177, Train Acc: 0.9538, Val Loss: 0.4426, Val Acc: 0.8256\n",
            "Epoch 8/10, Train Loss: 0.0678, Train Acc: 0.9834, Val Loss: 0.1329, Val Acc: 0.9487\n",
            "Epoch 9/10, Train Loss: 0.0895, Train Acc: 0.9621, Val Loss: 0.8874, Val Acc: 0.6718\n",
            "Epoch 10/10, Train Loss: 0.0701, Train Acc: 0.9728, Val Loss: 0.3260, Val Acc: 0.8667\n",
            "Test Accuracy: 0.8885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model using ResNet-50"
      ],
      "metadata": {
        "id": "O3nXu5bilpRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforams\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Define transformations for training and testing\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Set up dataset paths (assume images are organized into 'Control' and 'MS' subfolders)\n",
        "dataset_path = '/content/drive/MyDrive/dataset'\n",
        "\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=data_transforms['train'])\n",
        "\n",
        "\n",
        "# Split dataset (65% train, 15% validation, 20% test)\n",
        "train_size = int(0.65 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
        "\n",
        "# Load pretrained ResNet-50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)  # Modify output layer for binary classification (Healthy vs MS)\n",
        "\n",
        "# Set up training device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training and validation loop\n",
        "num_epochs = 10\n",
        "best_val_accuracy = 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_preds += torch.sum(preds == labels.data)\n",
        "        total_preds += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_accuracy = correct_preds.double() / len(train_loader.dataset)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_correct += torch.sum(preds == labels.data)\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = val_correct.double() / len(val_loader.dataset)\n",
        "\n",
        "    # Save the model if validation accuracy improves\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), 'best_resnet18_model.pth')\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "# Testing phase\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_correct += torch.sum(preds == labels.data)\n",
        "        test_total += labels.size(0)\n",
        "\n",
        "test_accuracy = test_correct.double() / len(test_loader.dataset)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Save final model after training\n",
        "torch.save(model.state_dict(), 'final_resnet18_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MdKMZhMDZCI",
        "outputId": "89ec9daf-ccb6-43c4-903f-b28dd066a7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 119MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.5450, Train Acc: 0.6935, Val Loss: 0.4773, Val Acc: 0.7538\n",
            "Epoch 2/10, Train Loss: 0.2904, Train Acc: 0.8710, Val Loss: 0.4080, Val Acc: 0.8205\n",
            "Epoch 3/10, Train Loss: 0.1526, Train Acc: 0.9467, Val Loss: 0.4640, Val Acc: 0.7744\n",
            "Epoch 4/10, Train Loss: 0.1122, Train Acc: 0.9574, Val Loss: 0.8215, Val Acc: 0.6872\n",
            "Epoch 5/10, Train Loss: 0.0948, Train Acc: 0.9669, Val Loss: 0.3230, Val Acc: 0.8821\n",
            "Epoch 6/10, Train Loss: 0.1715, Train Acc: 0.9349, Val Loss: 0.6044, Val Acc: 0.7282\n",
            "Epoch 7/10, Train Loss: 0.1044, Train Acc: 0.9633, Val Loss: 0.9403, Val Acc: 0.6923\n",
            "Epoch 8/10, Train Loss: 0.0668, Train Acc: 0.9740, Val Loss: 0.2108, Val Acc: 0.9026\n",
            "Epoch 9/10, Train Loss: 0.0180, Train Acc: 0.9953, Val Loss: 0.1913, Val Acc: 0.9333\n",
            "Epoch 10/10, Train Loss: 0.0825, Train Acc: 0.9775, Val Loss: 0.2458, Val Acc: 0.9231\n",
            "Test Accuracy: 0.8923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model.pth')\n"
      ],
      "metadata": {
        "id": "2hdUZ-BTZk5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models.vgg16"
      ],
      "metadata": {
        "id": "SgjQpA8WAwT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}